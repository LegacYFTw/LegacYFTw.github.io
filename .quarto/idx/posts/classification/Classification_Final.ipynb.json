{"title":"Classifying Bengali MNIST using a Hybrid Quantum Neural Network","markdown":{"yaml":{"title":"Classifying Bengali MNIST using a Hybrid Quantum Neural Network","description":"Classifying using quantum machine learning.","author":"Turbasu Chatterjee","date":"11/14/2023","toc":true,"categories":["class-project","machine-learning","classification","quantum-computing"]},"headingText":"Data Preprocessing","containsRefs":false,"markdown":"\n\n\nThe bengali language, commonly known as bangla is one which is spoken by the people native to the Bengal region of South Asia. It is the sixth most spoken native language and the seventh most spoken language in the world. Machine learning has seen tremendous advancements over the past decade, and one of the most exciting developments in the field is the fusion of quantum computing with traditional neural networks. Quantum computing's ability to process vast amounts of data and perform complex calculations has opened up new possibilities for solving real-world problems. In this post, we shall see how the juxtaposition of machine learning, quantum computing and the bengali language, i.e., my native language plays out.\n\nIn this blog, we shall use the bengali MNIST dataset from Kaggle to train a neural network with one convolution layer. But first, let us fetch the data from Kaggle.\n\nWe shall now unzip the dataset for our needs.\n\nOnce done, we shall import necessary libraries. In our case, we shall be using the ```torch``` library to build our neural network. This neural network would have a quantum layer in it which we shall use. This quantum layer is built using the ```qiskit``` library.\n\nIn this notebook, we shall rely on the GPU to speed up the training process for the classical convolution layers. Here we check if the ```CUDA``` is available for use by the ```torch``` library.\n\n\nOur dataset, as it turns out is a bunch of jpg pictures. In order for these images to be readable by the neural network, we shall convert them into image tensors, and associate each tensor with a label from the csv file provided. In this class we build  a ```BanglaMNISTDataset``` class that does exactly that with the using its private functions.\n\n\n\nIn this part, we first transform the image to grayscale, resize the images to dimensions 28 x 28 and then output a tensor.\n\nNow once we have achieved that, we shall use labelled data to train the classifier. This is done by making an object of the ```BanglaMNISTDataset``` and using labelled, transformed data.\n\nTo make sure, we did okay, we shall now check the data and make sure they are correctly associated with the labels.\n\nNow we use the same strategy to see if the test dataset is working correctly\n\n\n\n## The Quantum Layer\n\nIn this layer we shall define our quantum layer. Here we shall work with what is known as a quantum circuit for our logic synthesis. We shall input our data into the quantum layer using the what is known as *angle encoding*, where we use a Hadamard gate, thereby putting it in a state of superposition. Then we embed the features as an angle into the circuit. This will serve as a quantum convolution layer.\n\nWe can measure and visualize the circuit and find the expected value of our embedding.\n\nAll that is left is to interface the quantum layer with the neural network. In this case, we need to define the forward propagation and backward propagation methodology. We define our automatic differentiation for the backpropagation using the gradients to the expected value of the state post-measurement.\n\nNow, all that is left is to piece everything together and build the neural network using everything we have so far. We add 2 convolution layer, a dropout layer and at the end, a 10 qubit hybrid quantum convolution layer.\n\nA summary of the model is given as follows:\n\nNow we use the ```Adam``` optimizer and a ```CrossEntropyLoss``` to train the model on our dataset. This takes quite a bit of time, even with a GPU.\n\n## Visualization and Metrics\n\nNow that we have trained the model, we can see visualize how the model minimizes the losses.\n\nLet us now see the accuracy of the model.\n\nFinally, let us see how the model fares in testing. With an accuracy of around 84%, we dont expect a lot.\n\nIn conclusion, we can see that in this case, the quantum layer does not improve the performance by any stretch. This is due to several reasons: There is information loss whenever there we try any kind of embedding technique from classical to quantum data. This could be improved with the introduction of transfer learning but a quantum layer, in this case, does nothing but bring down the accuracy of a model.\n","srcMarkdownNoYaml":"\n\n\nThe bengali language, commonly known as bangla is one which is spoken by the people native to the Bengal region of South Asia. It is the sixth most spoken native language and the seventh most spoken language in the world. Machine learning has seen tremendous advancements over the past decade, and one of the most exciting developments in the field is the fusion of quantum computing with traditional neural networks. Quantum computing's ability to process vast amounts of data and perform complex calculations has opened up new possibilities for solving real-world problems. In this post, we shall see how the juxtaposition of machine learning, quantum computing and the bengali language, i.e., my native language plays out.\n\nIn this blog, we shall use the bengali MNIST dataset from Kaggle to train a neural network with one convolution layer. But first, let us fetch the data from Kaggle.\n\nWe shall now unzip the dataset for our needs.\n\nOnce done, we shall import necessary libraries. In our case, we shall be using the ```torch``` library to build our neural network. This neural network would have a quantum layer in it which we shall use. This quantum layer is built using the ```qiskit``` library.\n\nIn this notebook, we shall rely on the GPU to speed up the training process for the classical convolution layers. Here we check if the ```CUDA``` is available for use by the ```torch``` library.\n\n# Data Preprocessing\n\nOur dataset, as it turns out is a bunch of jpg pictures. In order for these images to be readable by the neural network, we shall convert them into image tensors, and associate each tensor with a label from the csv file provided. In this class we build  a ```BanglaMNISTDataset``` class that does exactly that with the using its private functions.\n\n\n\nIn this part, we first transform the image to grayscale, resize the images to dimensions 28 x 28 and then output a tensor.\n\nNow once we have achieved that, we shall use labelled data to train the classifier. This is done by making an object of the ```BanglaMNISTDataset``` and using labelled, transformed data.\n\nTo make sure, we did okay, we shall now check the data and make sure they are correctly associated with the labels.\n\nNow we use the same strategy to see if the test dataset is working correctly\n\n\n\n## The Quantum Layer\n\nIn this layer we shall define our quantum layer. Here we shall work with what is known as a quantum circuit for our logic synthesis. We shall input our data into the quantum layer using the what is known as *angle encoding*, where we use a Hadamard gate, thereby putting it in a state of superposition. Then we embed the features as an angle into the circuit. This will serve as a quantum convolution layer.\n\nWe can measure and visualize the circuit and find the expected value of our embedding.\n\nAll that is left is to interface the quantum layer with the neural network. In this case, we need to define the forward propagation and backward propagation methodology. We define our automatic differentiation for the backpropagation using the gradients to the expected value of the state post-measurement.\n\nNow, all that is left is to piece everything together and build the neural network using everything we have so far. We add 2 convolution layer, a dropout layer and at the end, a 10 qubit hybrid quantum convolution layer.\n\nA summary of the model is given as follows:\n\nNow we use the ```Adam``` optimizer and a ```CrossEntropyLoss``` to train the model on our dataset. This takes quite a bit of time, even with a GPU.\n\n## Visualization and Metrics\n\nNow that we have trained the model, we can see visualize how the model minimizes the losses.\n\nLet us now see the accuracy of the model.\n\nFinally, let us see how the model fares in testing. With an accuracy of around 84%, we dont expect a lot.\n\nIn conclusion, we can see that in this case, the quantum layer does not improve the performance by any stretch. This is due to several reasons: There is information loss whenever there we try any kind of embedding technique from classical to quantum data. This could be improved with the introduction of transfer learning but a quantum layer, in this case, does nothing but bring down the accuracy of a model.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"Classification_Final.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"zephyr","title":"Classifying Bengali MNIST using a Hybrid Quantum Neural Network","description":"Classifying using quantum machine learning.","author":"Turbasu Chatterjee","date":"11/14/2023","categories":["class-project","machine-learning","classification","quantum-computing"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}